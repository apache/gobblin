# Misc. deployment/cluster specific variables
user.name=kafkaetl
logs.user.name=kafkaetlstream
root.project.name=gobblin-kafka-streaming-local
grid.name=ltx1-holdem


# Cluster specific directory configurations
# home.dir and root.data.location should be unique per cluster deployment

# [DIFF] [Need to change this for making it work locally]
home.dir=/jobs/${user.name}
logs.dir=/jobs/${logs.user.name}
root.data.location=/data

fs.uri=file:///

# Yarn Configuration
gobblin.yarn.app.queue=default

# Gobblin Cluster

#Add a suffix "-1" to the app name becuase of a corrupted Helix cluster znode (LIZK-619). This made the helix cluster
# (and the deletion of znode) unusable. TODO - Once LIZK-619 is resolved, we can drop this property.
gobblin.yarn.app.name=${root.project.name}-${grid.name}-1

# Metrics Configuration
metrics.enabled=true
kafka.schema.registry.url=http://ltx1-schemaregistry-vip-1.corp.linkedin.com:12250/schemaRegistry/schemas
kafka.schema.registry.class=org.apache.gobblin.metrics.kafka.KafkaAvroSchemaRegistry
metrics.reporting.kafka.brokers=ltx1-kafka-kafka-local-metrics-vip.corp.linkedin.com:16637

# Hive Configurations
hive.tracking.database.name=kafka_streaming
hive.additional.daily_compaction.database.name=kafka_streaming_deduped

# GCS Configurations
gobblin.config.management.store.uri=ivy-hdfs:/?org=com.linkedin.gobblin-config-store&module=gobblin-hdfs-config-store&storePath=/jobs/etlconf&storePrefix=prod_CONFIG_STORE
gobblin.config.runtime.CLUSTER_NAME=holdem

#================================
#InGraphs Reporting configuration
#================================
amfServer.url=http://ltx1-amf.corp.linkedin.com:13131/api/v1
