#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# ====================================================================
# Job configurations
# ====================================================================

# Required configuration constraints
gobblin.template.required_attributes="job.work.dir,state.store.fs.uri,writer.fs.uri,kafka.schema.json,kafka.brokers,kafka.topics"

# Job info
job.name=KafkaHDFS
job.lock.enabled=false

# Gobblin data storage configurations
state.store.dir=${job.work.dir}/state-store
task.data.root.dir=${job.work.dir}/task-data
writer.staging.dir=${job.work.dir}/task-staging
writer.output.dir=${job.work.dir}/task-output
data.publisher.final.dir=${job.work.dir}/job-output

# Gobblin MapReduce configurations
mr.job.root.dir=${job.work.dir}/working
mr.job.lock.dir=${job.work.dir}/locks

# Source
source.class=org.apache.gobblin.source.extractor.extract.kafka.Kafka09JsonSource
source.kafka.json.schema=${kafka.schema.json}

topic.whitelist=${kafka.topics}
org.apache.gobblin.kafka.consumerClient.class="org.apache.gobblin.kafka.client.Kafka09ConsumerClient$Factory"
# Accepted values - latest, earliest and with offset lookback (latest offset - lookback)
bootstrap.with.offset=earliest
kafka.workunit.packer.type=SINGLE_LEVEL
mr.job.max.mappers=10

## Extract
extract.namespace=kafka
extract.table.type=SNAPSHOT_APPEND
extract.limit.type=time
extract.limit.enabled=true
extract.limit.timeLimit=5
extract.limit.timeLimitTimeunit=minutes

# Task execution configurations
taskexecutor.threadpool.size=4
taskretry.threadpool.coresize=1
taskretry.threadpool.maxsize=1

# Converter
converter.classes=org.apache.gobblin.converter.avro.JsonIntermediateToAvroConverter

# Writer
writer.destination.type=HDFS
writer.output.format=AVRO
writer.builder.class=org.apache.gobblin.writer.AvroDataWriterBuilder